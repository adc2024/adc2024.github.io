<!DOCTYPE html><html lang="en" class="bg-gray-200"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="preload" as="image" href="/images/melb.jpg"/><title>Tutorials | ADC 2023</title><meta name="description" content="Welcome to the 34th Australasian Database Conference, ADC 2023. The Australasian Database Conference (ADC) series is an annual forum for sharing the latest research progresses and novel applications of database systems, data management, data mining and data analytics for researchers and practitioners in these areas from Australia, New Zealand and in the world."/><meta property="og:title" content="Tutorials | ADC 2023"/><meta property="og:description" content="Welcome to the 34th Australasian Database Conference, ADC 2023. The Australasian Database Conference (ADC) series is an annual forum for sharing the latest research progresses and novel applications of database systems, data management, data mining and data analytics for researchers and practitioners in these areas from Australia, New Zealand and in the world."/><meta property="og:type" content="website"/><meta property="og:site_name" content="2023 "/><meta property="og:image" content="/thumbnail.jpg"/><meta property="og:url" content="https://adc2023.github.io/program/tutorials"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Tutorials | ADC 2023"/><meta name="twitter:description" content="Welcome to the 34th Australasian Database Conference, ADC 2023. The Australasian Database Conference (ADC) series is an annual forum for sharing the latest research progresses and novel applications of database systems, data management, data mining and data analytics for researchers and practitioners in these areas from Australia, New Zealand and in the world."/><meta name="twitter:creator" content="2023 Australasian Database Conference"/><meta name="twitter:image" content="/thumbnail.jpg"/><meta name="robots" content="follow, index"/><link rel="icon" href="/favicon.ico"/><meta name="next-head-count" content="18"/><link rel="preload" href="/fonts/inter-latin-variable-wghtOnly-normal.woff2" as="font" type="font/woff2" crossorigin="anonymous"/><link rel="preload" href="/_next/static/css/7181c6999132e779.css" as="style"/><link rel="stylesheet" href="/_next/static/css/7181c6999132e779.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer=""></script><script src="/_next/static/chunks/framework-114634acb84f8baa.js" defer=""></script><script src="/_next/static/chunks/main-7209515590abf48c.js" defer=""></script><script src="/_next/static/chunks/pages/_app-4ea82d03f64dafb8.js" defer=""></script><script src="/_next/static/chunks/248-75d7671cbee9593e.js" defer=""></script><script src="/_next/static/chunks/628-78242661a27dab8e.js" defer=""></script><script src="/_next/static/chunks/pages/program/tutorials-6f7ef65cedccd582.js" defer=""></script><script src="/_next/static/mYg7ParIJu1TTTHhUOiiF/_buildManifest.js" defer=""></script><script src="/_next/static/mYg7ParIJu1TTTHhUOiiF/_ssgManifest.js" defer=""></script></head><body class=""><div id="__next"><div class="min-h-screen flex flex-col"><header><div class="max-w-[70em] h-[4em] mx-auto flex justify-between pr-3.5"><div class="bg-gray-900 px-5 py-1 flex flex-col items-center justify-center"><h1 class="text-3xl font-bold block"><span class="text-gray-200">A</span><span class="text-gray-300">D</span><span class="text-gray-400">C</span><span class="text-orange-600">2023</span></h1><p class="text-gray-500 font-semibold block text-xs mt-[-0.2em]">Melbourne, AU</p></div><div class="flex"><nav class="h-[4em] hidden md:flex items-center justify-end w-full text-gray-900"><ul class="flex justify-center h-full items-center"><li class="text-sm font-bold uppercase tracking-wider hover:text-orange-600 duration-100"><a class="pl-1 pr-1 lg:pl-2.5 lg:pr-2.5 py-2" href="/">Home</a></li><li class="relative ml-3 group" data-headlessui-state=""><div><button class="text-sm font-bold uppercase tracking-wider group-hover:text-orange-600 duration-100 flex items-center pl-1 pr-1 lg:pl-2.5 lg:pr-2.5 py-2 space-x-0.5" id="headlessui-menu-button-:R56am:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Submission</span><span class="">Submission</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class="w-4 h-4"><path stroke-linecap="round" stroke-linejoin="round" d="M19.5 8.25l-7.5 7.5-7.5-7.5"></path></svg></button></div></li><li class="relative group" data-headlessui-state=""><div><button class="text-sm font-bold uppercase tracking-wider group-hover:text-orange-600 duration-100 flex items-center pl-1 pr-1 lg:pl-2.5 lg:pr-2.5 py-2 space-x-0.5" id="headlessui-menu-button-:R5mam:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Program</span><span class="">Program</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class="w-4 h-4"><path stroke-linecap="round" stroke-linejoin="round" d="M19.5 8.25l-7.5 7.5-7.5-7.5"></path></svg></button></div></li><li class="relative group" data-headlessui-state=""><div><button class="text-sm font-bold uppercase tracking-wider group-hover:text-orange-600 duration-100 flex items-center pl-1 pr-1 lg:pl-2.5 lg:pr-2.5 py-2 space-x-0.5" id="headlessui-menu-button-:R66am:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Attend</span><span class="">Attend</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class="w-4 h-4"><path stroke-linecap="round" stroke-linejoin="round" d="M19.5 8.25l-7.5 7.5-7.5-7.5"></path></svg></button></div></li><li class="relative group" data-headlessui-state=""><div><button class="text-sm font-bold uppercase tracking-wider group-hover:text-orange-600 duration-100 flex items-center pl-1 pr-1 lg:pl-2.5 lg:pr-2.5 py-2 space-x-0.5" id="headlessui-menu-button-:R6mam:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Organisation</span><span class="">Organisation</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class="w-4 h-4"><path stroke-linecap="round" stroke-linejoin="round" d="M19.5 8.25l-7.5 7.5-7.5-7.5"></path></svg></button></div></li></ul></nav><nav class="h-[4em] flex md:hidden" style="z-index:9999"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class="w-8 h-8 m-auto hover:text-orange-600 cursor-pointer"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg></nav></div></div><div class="h-[500px] w-full absolute top-[4em]"><img alt="" src="/images/melb.jpg" width="2400" height="1798" decoding="async" data-nimg="1" class="w-full h-full object-cover" style="color:transparent"/></div></header><main class="bg-gray-50 max-w-[70em] w-full min-h-[500px] mx-auto relative"><div class="px-5 md:px-8 lg:px-10"><h2 class="mt-10 md:mt-14 uppercase text-3xl font-bold text-orange-600 tracking-wide mb-8">Tutorials</h2><article class="pb-16"><h3 class="font-bold text-2xl text-gray-800 mb-2">Towards Data-centric Graph Machine Learning</h3><p class="text-sm mb-6">Wed 1 Nov 2023 10:30 AEDT (UTC+11)</p><h3 class="font-bold text-xl text-gray-600 mb-4">▶  Abstract</h3><p class="px-0 md:px-7">Graph-structured data, constituted by discrete nodes connected by independent edges within a non-Euclidean space, serves as the foundational data type for depicting and capturing complex interdependencies among massive diverse entities in the real world. In the context of Data-centric AI, this tutorial will provide an introduction of the recent advances in Data-centric Graph Machine Learning (DC-GML). Concretely, this tutorial will cover the systematic framework of DC-GML that encompasses all stages of the graph data lifecycle, including graph data collection, exploration, improvement, exploitation, and maintenance. Three critical graph-centric questions will be answered covering: (1) how to enhance graph data availability and quality; (2) how to learn from graph data with limited-availability and low-quality; (3) how to build graph MLOps systems from the graph data-centric view. Lastly, this tutorial will offer a forward-looking outlook to navigate future advancements and applications of the DC-GML domain.</p><h3 class="mt-7 font-bold text-xl text-gray-600 mb-5">▶  Speakers</h3><div class="px-0 md:px-7 flex gap-x-10 gap-y-5 flex-wrap"><div class="flex w-[20em] sm:w-[25em]"><a class="border rounded-lg overflow-hidden mr-3 min-w-[60px] min-h-[60px] w-[60px] h-[60px] bg-gray-200" href="https://shiruipan.github.io/" target="_blank" rel="noreferrer"><img alt="" src="/images/committee/shirui-pan.jpg" width="60" height="60" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a><div class="flex flex-col justify-center"><span class="text-gray-800 font-bold text-lg">Shirui Pan</span><span class="text-gray-600 text-sm">Griffith University</span></div></div><div class="flex w-[20em] sm:w-[25em]"><a class="border rounded-lg overflow-hidden mr-3 min-w-[60px] min-h-[60px] w-[60px] h-[60px] bg-gray-200" href="https://shiruipan.github.io/authors/xin-zheng/" target="_blank" rel="noreferrer"><img alt="" src="/images/committee/xin-zheng.jpg" width="60" height="60" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a><div class="flex flex-col justify-center"><span class="text-gray-800 font-bold text-lg">Xin Zheng</span><span class="text-gray-600 text-sm">Monash University</span></div></div></div><p class="mt-4 px-0 md:px-7">Shirui Pan is a Professor and an ARC Future Fellow with the School of Information and Communication Technology, Griffith University, Australia. He received his Ph.D degree in computer science from University of Technology Sydney (UTS), Australia. He is a Senior Member of IEEE and ACM, and a Fellow of Queensland Academy of Arts and Sciences (FQA). Shirui’s research focuses on artificial intelligence, with a focus on graph machine learning. His research has been published in top conferences and journals including NeurIPS, ICML, KDD, TPAMI, TNNLS, and TKDE. His research received the 2024 IEEE CIS TNNLS Outstanding Paper Award and the IEEE ICDM Best Student Paper Award.</p><p class="mt-4 px-0 md:px-7">Xin Zheng is a final year Ph.D. student at Monash University, Australia. She received her B.S degree (2017) and Master degree (2020) both from Dalian University of Technology, China. Her research interests mainly on the study of automated graph machine learning operations (MLOps) workflow, specifically within the automated GNN design and graph data-centric learning. She has published papers on top-tier journals and conference papers, such as IJCV, PR, ICDM, WWW, MM.</p><div class="border-t-2 border-dotted mt-16 mb-8 bg-gray-400 mx-[-1em]"></div><p class="text-orange-600 uppercase tracking-[0.2em] mb-2 font-semibold">TUTORIAL</p><h3 class="font-bold text-2xl text-gray-800 mb-2">Detect Label Errors in Datasets</h3><p class="text-sm mb-6">Wed 1 Nov 2023 13:00 AEDT (UTC+11)</p><h3 class="font-bold text-xl text-gray-600 mb-4">▶  Abstract</h3><p class="px-0 md:px-7">With the rise of large AI models, data assets have gained increasing importance. Understanding how to identify and correct label errors in our datasets is crucial. This is primarily because label errors are pervasive in the era of big data, and rectifying them can significantly enhance our knowledge. Moreover, large AI models are susceptible to overfitting label errors, which hinders their ability to generalize effectively unless label noise is adequately addressed. In this tutorial, we will present typical approaches to handle label noise, such as extracting confident/non-confident examples (indicating likely correct/incorrect labels) using deep network properties and intuitions. Additionally, we will explore methods that focus on directly modelling the label noise, providing theoretical guarantees. By illustrating the intuitions behind state-of-the-art techniques, this tutorial aims to equip researchers and practitioners with valuable insights into effectively managing label noise in datasets.</p><h3 class="mt-7 font-bold text-xl text-gray-600 mb-5">▶  Speaker</h3><div class="flex w-[20em] sm:w-[25em] px-0 md:px-7"><a class="border rounded-lg overflow-hidden mr-3 min-w-[60px] min-h-[60px] w-[60px] h-[60px] bg-gray-200" href="https://tongliang-liu.github.io/" target="_blank" rel="noreferrer"><img alt="" src="/images/committee/tongliang-liu.jpg" width="60" height="60" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a><div class="flex flex-col justify-center"><span class="text-gray-800 font-bold text-lg">Tongliang Liu</span><span class="text-gray-600 text-sm">University of Sydney</span></div></div><p class="mt-4 px-0 md:px-7">Tongliang Liu is the Director of Sydney AI Centre at the University of Sydney. He is broadly interested in the fields of trustworthy machine learning and its interdisciplinary applications, with a particular emphasis on learning with noisy labels, adversarial learning, transfer learning, unsupervised learning, and statistical deep learning theory. He has authored and co-authored more than 200 research articles including ICML, NeurIPS, ICLR, CVPR, AAAI, IJCAI, JMLR, and TPAMI. His monograph on machine learning with noisy labels will be published by MIT Press. He is/was a (senior-) meta reviewer for many conferences, such as ICML, NeurIPS, ICLR, UAI, AAAI, IJCAI, and KDD, and was a notable AC for ICLR. He is an Associate Editor of TMLR and is on the Editorial Boards of JMLR and MLJ. He is a recipient of the AI’s 10 to Watch Award from IEEE in 2023, the Future Fellowship Award from Australian Research Council (ARC) in 2022, and the Discovery Early Career Researcher Award (DECRA) from ARC in 2018.</p><div class="border-t-2 border-dotted mt-16 mb-8 bg-gray-400 mx-[-1em]"></div><p class="text-orange-600 uppercase tracking-[0.2em] mb-2 font-semibold">TUTORIAL</p><h3 class="font-bold text-2xl text-gray-800 mb-2">Data-centric Computer Vision: Problems, Good Practices and Preliminary Solutions</h3><p class="text-sm mb-6">Wed 1 Nov 2023 15:30 AEDT (UTC+11)</p><h3 class="font-bold text-xl text-gray-600 mb-4">▶  Abstract</h3><p class="px-0 md:px-7">As the demand for data-driven decision-making and artificial intelligence applications continues to rise, the importance of data cannot be understated. This tutorial will provide a comprehensive overview of the key principles, good practices, and challenges associated with data-centric computer vision problems. On the one hand, this tutorial gives a few examples of data properties, such as image-text alignment strength, test data difficulty and training data quality. On the other hand, we will discuss collecting, cleaning, organizing, and validating data to improve its reliability and relevance for specific applications. Through two representative cases, one in domain generalization and one in medical imaging data, this tutorial will demonstrate how to curate high-quality and useful datasets for future research.</p><h3 class="mt-7 font-bold text-xl text-gray-600 mb-5">▶  Speakers</h3><div class="px-0 md:px-7 flex gap-x-10 gap-y-5 flex-wrap"><div class="flex w-[20em] sm:w-[25em]"><a class="border rounded-lg overflow-hidden mr-3 min-w-[60px] min-h-[60px] w-[60px] h-[60px] bg-gray-200" href="https://sites.google.com/view/xinyus-homepage/Home" target="_blank" rel="noreferrer"><img alt="" src="/images/committee/xin-yu.png" width="60" height="60" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a><div class="flex flex-col justify-center"><span class="text-gray-800 font-bold text-lg">Xin Yu</span><span class="text-gray-600 text-sm">University of Queensland</span></div></div><div class="flex w-[20em] sm:w-[25em]"><a class="border rounded-lg overflow-hidden mr-3 min-w-[60px] min-h-[60px] w-[60px] h-[60px] bg-gray-200" href="https://zheng-lab.cecs.anu.edu.au/" target="_blank" rel="noreferrer"><img alt="" src="/images/committee/liang-zheng.jpg" width="60" height="60" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a><div class="flex flex-col justify-center"><span class="text-gray-800 font-bold text-lg">Liang Zheng</span><span class="text-gray-600 text-sm">Australian National University</span></div></div><div class="flex w-[20em] sm:w-[25em]"><a class="border rounded-lg overflow-hidden mr-3 min-w-[60px] min-h-[60px] w-[60px] h-[60px] bg-gray-200" href="https://scholar.google.com/citations?user=OfTXHvsAAAAJ&amp;hl=en" target="_blank" rel="noreferrer"><img alt="" src="/images/committee/zijian-wang.png" width="60" height="60" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a><div class="flex flex-col justify-center"><span class="text-gray-800 font-bold text-lg">Zijian Wang</span><span class="text-gray-600 text-sm">University of Queensland</span></div></div></div><p class="mt-4 px-0 md:px-7">Dr Xin Yu is a Senior Lecturer at the University of Queensland (UQ) and is an ARC DECRA fellow. Previously, he was a research fellow at the Australian National University (ANU). He received PhD degrees from Tsinghua University and the Australian National University, respectively. His research interests cover a wide range of topics in Computer Vision and Machine Learning. He has published more than 70 papers on top-tier conference papers and journals, such as CVPR, ECCV, NeurIPS, ICLR, TPAMI, and IJCV. He also received Best Paper Honorable Mention Award in WACV 2020, and his paper was nominated for the Best Paper Award in CVPR 2020. He is a recipient of Google Research Scholar Award in 2021. He also won several Challenge championships in the workshops of CVPR, ACCV, etc.</p><p class="mt-4 px-0 md:px-7">Dr Liang Zheng is a Senior Lecturer and was an ARC DECRA Fellow in the Australian National University. He is best known for his contributions in object re-identification, where he and his collaborators designed widely used datasets and algorithms such as Market-1501 (ICCV 2015), part-based convolutional baseline (ECCV 2018), random erasing (AAAI 2020) and joint detection and embedding (ECCV 2020). His recent research interest is data-centric computer vision, aiming at analysing and improving data rather than models themselves. He is a leading organizer of the Vision Datasets Understanding workshop series and the DataCV challenge at CVPR and serves as an Area Chair for leading conferences such as CVPR, ICCV, ECCV and NeurIPS. He received the Outstanding Young Author (Paper) Award from IEEE Transactions on Circuits and Systems for Video Technology and was named one of AI’s 10 to Watch by IEEE Intelligent Systems and Australia’s Early Achievers by The Australian. He received his B.S degree (2010) and Ph.D degree (2015) both from Tsinghua University, China.</p><p class="mt-4 px-0 md:px-7">Zijian Wang is a Postdoctoral Research Fellow at the University of Queensland (UQ). His PhD thesis is mainly on domain adaptation and generalization in computer vision. He has published papers on top-tier conference papers and journals, such as ICCV, ICML, ICLR, MM, and TPAMI. Zijian has also been widely engaged in a number of cross-disciplinary research projects, spanning civil engineering and chemical engineering.</p><div class="border-t-2 border-dotted mt-16 mb-8 bg-gray-400 mx-[-1em]"></div><p class="text-orange-600 uppercase tracking-[0.2em] mb-2 font-semibold">TUTORIAL</p><h3 class="font-bold text-2xl text-gray-800 mb-2">Towards Trustworthy Data Markets: Recent Advances and Open Problems</h3><p class="text-sm mb-6">Thu 2 Nov 2023 10:30 AEDT (UTC+11)</p><h3 class="font-bold text-xl text-gray-600 mb-4">▶  Abstract</h3><p class="px-0 md:px-7">Data is the new oil. The value of data is rapidly increasing, with companies like Google and Facebook surpassing traditional oil companies in market capitalization and ranking on the Fortune 500 list. As the data science community explores ways to determine, transfer, and allocate the value of data, new technical challenges arise when considering the economic constraints in the data science pipeline, including data collection, cleaning, sharing, and analysis. One of the biggest hurdles in data markets is exchanging sensitive data related to individuals, such as social networks, spatiotemporal trajectories, and healthcare information. In this tutorial, I will discuss recent studies on creating a trustworthy data market that enables private, secure, and fair data trading. We will also examine areas for further research and opportunities to improve the current state of the data market.</p><h3 class="mt-7 font-bold text-xl text-gray-600 mb-5">▶  Speaker</h3><div class="px-0 md:px-7 flex gap-x-10 gap-y-5 flex-wrap"><div class="flex w-[20em] sm:w-[25em]"><a class="border rounded-lg overflow-hidden mr-3 min-w-[60px] min-h-[60px] w-[60px] h-[60px] bg-gray-200 flex justify-center" href="https://yangcao88.github.io/" target="_blank" rel="noreferrer"><img alt="" src="/images/committee/yang-cao.jpg" width="44.63" height="60" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a><div class="flex flex-col justify-center"><span class="text-gray-800 font-bold text-lg">Yang Cao</span><span class="text-gray-600 text-sm">Hokkaido University</span></div></div></div><p class="mt-4 px-0 md:px-7">Yang Cao is an Associate Professor at Hokkaido University. He earned his Ph.D. in Informatics from Kyoto University in 2017. His research areas include security and privacy, data markets, data management, and trustworthy machine learning. His work has been published in esteemed conferences and journals such as VLDB, SIGMOD, ICDE, KDD, AAAI, and USENIX Security. Three of his papers were finalists for best papers in ICDE 2017, ICME 2020, and BigData 2022. He has received several awards, including the IEEE Computer Society Japan Chapter Young Author Award in 2019 and the Database Society of Japan Kambayashi Young Researcher Award in 2021. His research projects have been supported by various organizations, including JSPS, JST, MSRA, KDDI, LINE, and WeBank.</p><div class="border-t-2 border-dotted mt-16 mb-8 bg-gray-400 mx-[-1em]"></div><p class="text-orange-600 uppercase tracking-[0.2em] mb-2 font-semibold">TUTORIAL</p><h3 class="font-bold text-2xl text-gray-800 mb-2">Privacy Challenges in Graph Neural Networks in MLaaS</h3><p class="text-sm mb-6">Thu 2 Nov 2023 13:00 AEDT (UTC+11)</p><h3 class="font-bold text-xl text-gray-600 mb-4">▶  Abstract</h3><p class="px-0 md:px-7">Graph Neural Networks (GNNs) have established themselves as influential graph learning tools with applications spanning from common utilities such as recommendation systems and advanced domains like drug discovery. As the adoption of GNNs in data-sensitive areas increases, their privacy considerations have garnered more focus. Recent research indicates that GNN models might be susceptible to privacy risks, emphasising the need to ensure the privacy of sensitive data, including model parameters and graph information. Two primary challenges in GNN privacy are: (1) the protection of diverse objectives like nodes, edges, graphs, and models, each with its unique requirements; and (2) the delicate balance between privacy and model utilities. In this tutorial, we aim to offer a comprehensive overview of existing GNN privacy methodologies and to shed light on unresolved challenges and emerging trends.</p><h3 class="mt-7 font-bold text-xl text-gray-600 mb-5">▶  Speakers</h3><div class="px-0 md:px-7 flex gap-x-10 gap-y-5 flex-wrap"><div class="flex w-[20em] sm:w-[25em]"><a class="border rounded-lg overflow-hidden mr-3 min-w-[60px] min-h-[60px] w-[60px] h-[60px] bg-gray-200" href="https://shiruipan.github.io/authors/bang-wu/" target="_blank" rel="noreferrer"><img alt="" src="/images/committee/bang-wu.jpg" width="60" height="60" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a><div class="flex flex-col justify-center"><span class="text-gray-800 font-bold text-lg">Bang Wu</span><span class="text-gray-600 text-sm">CSIRO - Data61</span></div></div><div class="flex w-[20em] sm:w-[25em]"><a class="border rounded-lg overflow-hidden mr-3 min-w-[60px] min-h-[60px] w-[60px] h-[60px] bg-gray-200" href="https://shiruipan.github.io/authors/he-zhang/" target="_blank" rel="noreferrer"><img alt="" src="/images/committee/he-zhang.jpg" width="60" height="60" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a><div class="flex flex-col justify-center"><span class="text-gray-800 font-bold text-lg">He Zhang</span><span class="text-gray-600 text-sm">Monash University</span></div></div></div><p class="mt-4 px-0 md:px-7">Bang Wu currently holds CSIRO Early Research Career (CERC) Postdoctoral Fellowship at CSIRO’s DATA61, Australia. His PhD thesis is mainly on securing graph neural networks in machine learning as a service. He has authored research papers featured in top-tier conferences and journals spanning multiple domains, including ICDM, ICML, AsiaCCS, TIFS, and TDSC. His research interests include trustworthy graph-based machine learning, trustworthy machine learning on multimodal systems, and various facets of security and privacy in machine learning across different domains.</p><p class="mt-4 px-0 md:px-7">He Zhang is a final year Ph.D. candidate at the Faculty of Information Technology, Monash University, Australia. He has a profound interest in GNNs and the development of trustworthy AI systems. His research in trustworthy GNNs has led to several academic publications in top conferences like ICML and CIKM, as well as top journals like IEEE TKDE. Currently, He Zhang is exploring the navigation in multiple objectives (e.g., privacy, fairness, and utility) with the aim of comprehensively building trustworthy GNNs.</p></article></div></main><footer class="max-w-[70em] mx-auto pt-8 pb-32 w-full"><div class="mx-5 flex flex-col md:flex-row gap-y-2 lg:px-0 items-start justify-between text-gray-600"><small class=""><span class="font-defaultSans">©</span> 1990-2023 Australasian Database Conference. <br class="block sm:hidden"/>All Rights Reserved.<span class="mt-2 hidden"> Cover photo by Dmitry Osipenko on Unsplash.</span></small><small><a href="https://dblp.uni-trier.de/db/conf/adc/index.html" target="_blank" rel="noreferrer" class="hover:underline flex space-x-1 items-center"><span>Previous Conferences</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-3 h-3"><path fill-rule="evenodd" d="M4.25 5.5a.75.75 0 00-.75.75v8.5c0 .414.336.75.75.75h8.5a.75.75 0 00.75-.75v-4a.75.75 0 011.5 0v4A2.25 2.25 0 0112.75 17h-8.5A2.25 2.25 0 012 14.75v-8.5A2.25 2.25 0 014.25 4h5a.75.75 0 010 1.5h-5z" clip-rule="evenodd"></path><path fill-rule="evenodd" d="M6.194 12.753a.75.75 0 001.06.053L16.5 4.44v2.81a.75.75 0 001.5 0v-4.5a.75.75 0 00-.75-.75h-4.5a.75.75 0 000 1.5h2.553l-9.056 8.194a.75.75 0 00-.053 1.06z" clip-rule="evenodd"></path></svg></a></small></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/program/tutorials","query":{},"buildId":"mYg7ParIJu1TTTHhUOiiF","nextExport":true,"autoExport":true,"isFallback":false,"scriptLoader":[]}</script></body></html>